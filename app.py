# app.py (PhiÃªn báº£n 4.0 - Cáº¥p Ä‘á»™ 3: ÄÃ£ thÃªm RAG Há»i-Ä‘Ã¡p PDF)

import streamlit as st
from google import genai
from PIL import Image
import io
import os

# --- ThÆ° viá»‡n má»›i cho Cáº¥p Ä‘á»™ 3 (RAG) ---
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains.question_answering import load_qa_chain
from PyPDF2 import PdfReader
# ----------------------------------------

# --- HÃ m phÃ¢n tÃ­ch lÃµi (HÃ¬nh áº£nh) - Giá»¯ nguyÃªn ---
def analyze_bio_image_streamlit(api_key, image_data, user_prompt, context_role):
    try:
        client = genai.Client(api_key=api_key) 
    except Exception as e:
        st.error(f"Lá»—i xÃ¡c thá»±c API Key (HÃ¬nh áº£nh): {e}")
        return

    system_instruction = (
        f"Báº¡n lÃ  Trá»£ lÃ½ AI Sinh há»c THPT (BioScope AI). HÃ£y tráº£ lá»i vá»›i vai trÃ² lÃ  má»™t chuyÃªn gia {context_role}. "
        f"PhÃ¢n tÃ­ch hÃ¬nh áº£nh, sá»­ dá»¥ng kiáº¿n thá»©c Sinh há»c THPT. ÄÆ°a ra nháº­n Ä‘á»‹nh chÃ­nh xÃ¡c vÃ  Ä‘áº·t cÃ¢u há»i/gá»£i Ã½ phÃ¹ há»£p."
    )
    img = Image.open(image_data)
    response = client.models.generate_content(
        model='gemini-2.5-flash',
        contents=[user_prompt, img],
        config={"system_instruction": system_instruction, "temperature": 0.5}
    )
    return response.text

# --- HÃ m má»›i cho Cáº¥p Ä‘á»™ 3 (Xá»­ lÃ½ PDF) ---
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

# --- HÃ m má»›i cho Cáº¥p Ä‘á»™ 3 (Chia chunks) ---
def get_text_chunks(text):
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)
    chunks = text_splitter.split_text(text)
    return chunks

# --- HÃ m má»›i cho Cáº¥p Ä‘á»™ 3 (Táº¡o Vector Store) ---
def get_vector_store(text_chunks, api_key):
    try:
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
        vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)
        # LÆ°u vÃ o session_state Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
        st.session_state.vector_store = vector_store
        st.sidebar.success("ÄÃ£ xá»­ lÃ½ xong tÃ i liá»‡u PDF!")
    except Exception as e:
        st.sidebar.error(f"Lá»—i táº¡o Vector Store: {e}")

# --- HÃ m má»›i cho Cáº¥p Ä‘á»™ 3 (Xá»­ lÃ½ cÃ¢u há»i RAG) ---
def answer_pdf_question(api_key, user_question):
    try:
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key, temperature=0.3)
        chain = load_qa_chain(llm, chain_type="stuff")
        # Láº¥y vector_store tá»« session_state
        vector_store = st.session_state.vector_store
        docs = vector_store.similarity_search(user_question)
        response = chain.run(input_documents=docs, question=user_question)
        return response
    except Exception as e:
        return f"Lá»—i khi tráº£ lá»i cÃ¢u há»i: {e}"

# --- Cáº¥u hÃ¬nh Trang & API Key ---
st.set_page_config(page_title="BioScope AI", layout="wide")

# Láº¥y API Key tá»« Secrets
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("Lá»—i: KhÃ´ng tÃ¬m tháº¥y GEMINI_API_KEY. Vui lÃ²ng thÃªm vÃ o Streamlit Secrets.")
    st.stop() # Dá»«ng á»©ng dá»¥ng náº¿u khÃ´ng cÃ³ API Key

# --- Giao diá»‡n Sidebar (ÄÃ£ nÃ¢ng cáº¥p Cáº¥p 3) ---
st.sidebar.title("ğŸ”¬ Giá»›i thiá»‡u BioScope AI")
st.sidebar.info(
    """
    ÄÃ¢y lÃ  cÃ´ng cá»¥ AI 2-trong-1: 
    1. **PhÃ¢n tÃ­ch HÃ¬nh áº£nh** (Tab chÃ­nh).
    2. **Há»i-Ä‘Ã¡p TÃ i liá»‡u PDF** (Má»›i!)
    """
)
st.sidebar.markdown("---")

# --- TÃ­nh nÄƒng Cáº¥p 3 (Táº£i PDF lÃªn Sidebar) ---
st.sidebar.subheader("ğŸ“š TÃ­nh nÄƒng Há»i-Ä‘Ã¡p TÃ i liá»‡u")
st.sidebar.write("Táº£i lÃªn file PDF (vÃ­ dá»¥: SÃ¡ch giÃ¡o khoa, sÃ¡ch Campbell) Ä‘á»ƒ AI Ä‘á»c vÃ  tráº£ lá»i cÃ¢u há»i.")
pdf_docs = st.sidebar.file_uploader("Táº£i lÃªn file PDF cá»§a báº¡n", accept_multiple_files=True, type="pdf")

if st.sidebar.button("Xá»­ lÃ½ TÃ i liá»‡u PDF"):
    if pdf_docs:
        with st.sidebar.spinner("Äang Ä‘á»c vÃ  phÃ¢n tÃ­ch PDF... (CÃ³ thá»ƒ máº¥t vÃ i phÃºt)"):
            raw_text = get_pdf_text(pdf_docs)
            text_chunks = get_text_chunks(raw_text)
            get_vector_store(text_chunks, GEMINI_API_KEY)
    else:
        st.sidebar.warning("Vui lÃ²ng táº£i lÃªn Ã­t nháº¥t má»™t file PDF.")

st.sidebar.markdown("---")
st.sidebar.subheader("ThÃ´ng tin tÃ¡c giáº£")
st.sidebar.write("Tráº§n Thá»¥y ÄÃ´ng HÃ²a")
st.sidebar.write("TrÆ°á»ng THPT Marie Curie")
st.sidebar.write("Email: hoattd@thptmariecuriehem.edu.vn")

# --- Giao diá»‡n chÃ­nh (Chia lÃ m 2 Tab) ---
st.title("ğŸ”¬ BioScope AI: Trá»£ lÃ½ AI Sinh há»c THPT")

tab1, tab2 = st.tabs(["ğŸ–¼ï¸ PhÃ¢n tÃ­ch HÃ¬nh áº£nh (Cáº¥p 2)", "ğŸ“š Há»i-Ä‘Ã¡p TÃ i liá»‡u (Cáº¥p 3 Má»šI)"])

# --- TAB 1: PHÃ‚N TÃCH HÃŒNH áº¢NH (NhÆ° Cáº¥p 2) ---
with tab1:
    st.header("Chá»©c nÄƒng PhÃ¢n tÃ­ch HÃ¬nh áº£nh & Cháº¥m Ä‘iá»ƒm")
    
    uploaded_file = st.file_uploader("1. Táº£i lÃªn hÃ¬nh áº£nh tiÃªu báº£n/thÃ­ nghiá»‡m:", type=["png", "jpg", "jpeg"])

    if uploaded_file:
        col_input, col_output = st.columns([2, 3]) 

        with col_input:
            st.subheader("Báº£ng Ä‘iá»u khiá»ƒn")
            st.image(uploaded_file, caption=f"áº¢nh Ä‘Ã£ táº£i lÃªn: {uploaded_file.name}", use_column_width=True)
            role = st.radio(
                "2. Chá»n Vai trÃ² (Tá»‘i Æ°u hÃ³a pháº£n há»“i AI):",
                ("Há»c sinh (Tá»± há»c & Kiá»ƒm tra)", "GiÃ¡o viÃªn (Kiá»ƒm tra & Táº¡o tÆ° liá»‡u)")
            )
            
            if role == "Há»c sinh (Tá»± há»c & Kiá»ƒm tra)":
                context = "Há»c sinh tá»± há»c"
                default_prompt = "ÄÃ¢y cÃ³ pháº£i lÃ  tiÃªu báº£n/thÃ­ nghiá»‡m Ä‘Ãºng khÃ´ng? HÃ£y giáº£i thÃ­ch hiá»‡n tÆ°á»£ng vÃ  Ä‘áº·t cho tÃ´i 2 cÃ¢u há»i Ã´n táº­p."
            else:
                context = "GiÃ¡o viÃªn chuyÃªn mÃ´n"
                default_prompt = "ÄÃ¡nh giÃ¡ tÃ­nh chÃ­nh xÃ¡c. Náº¿u Ä‘Ãºng, gá»£i Ã½ má»™t hoáº¡t Ä‘á»™ng tiáº¿p theo. Náº¿u sai, giáº£i thÃ­ch lá»—i sai sinh há»c cÆ¡ báº£n."
                
            prompt = st.text_area("3. CÃ¢u há»i chi tiáº¿t cá»§a báº¡n:", default_prompt, height=150)
            request_scoring = st.checkbox("ğŸ”¬ YÃªu cáº§u AI cháº¥m Ä‘iá»ƒm hÃ¬nh áº£nh (Thang 10)")
            submit_button = st.button("4. PhÃ¢n tÃ­ch HÃ¬nh áº£nh")

        with col_output:
            st.subheader("Káº¿t quáº£ phÃ¢n tÃ­ch HÃ¬nh áº£nh")
            
            if submit_button: 
                if prompt:
                    with st.spinner('Äang phÃ¢n tÃ­ch hÃ¬nh áº£nh báº±ng Gemini AI...'):
                        final_prompt_to_ai = prompt
                        if request_scoring:
                            scoring_instruction = (
                                "\n\n--- YÃŠU Cáº¦U CHáº¤M ÄIá»‚M ---"
                                "\nVá»›i vai trÃ² lÃ  má»™t giÃ¡o viÃªn Sinh há»c chuyÃªn nghiá»‡p, hÃ£y cháº¥m Ä‘iá»ƒm hÃ¬nh áº£nh nÃ y theo thang 10."
                                "\nTiÃªu chÃ­ cháº¥m Ä‘iá»ƒm: 1. TÃ­nh chÃ­nh xÃ¡c Sinh há»c. 2. Äá»™ rÃµ nÃ©t cá»§a áº£nh chá»¥p. 3. Má»©c Ä‘á»™ thÃ nh cÃ´ng cá»§a thÃ­ nghiá»‡m."
                                "\nHÃ£y tráº£ lá»i theo cáº¥u trÃºc sau:"
                                "\n**Äiá»ƒm sá»‘:** [Äiá»ƒm]/10"
                                "\n**Nháº­n xÃ©t chi tiáº¿t:** [Giáº£i thÃ­ch táº¡i sao, chá»‰ rÃµ Æ°u Ä‘iá»ƒm vÃ  nhÆ°á»£c Ä‘iá»ƒm]"
                            )
                            final_prompt_to_ai += scoring_instruction
                        
                        result = analyze_bio_image_streamlit(GEMINI_API_KEY, uploaded_file, final_prompt_to_ai, context)
                        st.success("PhÃ¢n tÃ­ch HoÃ n thÃ nh!")
                        with st.expander("Báº¥m vÃ o Ä‘Ã¢y Ä‘á»ƒ xem káº¿t quáº£ chi tiáº¿t", expanded=True):
                            st.markdown(result)
                else:
                    st.error("Vui lÃ²ng nháº­p cÃ¢u há»i chi tiáº¿t.")
            else:
                st.info("Káº¿t quáº£ phÃ¢n tÃ­ch cá»§a AI sáº½ xuáº¥t hiá»‡n táº¡i Ä‘Ã¢y sau khi báº¡n nháº¥n nÃºt.")

# --- TAB 2: Há»I-ÄÃP TÃ€I LIá»†U (Cáº¥p 3 Má»šI) ---
with tab2:
    st.header("Chá»©c nÄƒng Há»i-Ä‘Ã¡p dá»±a trÃªn TÃ i liá»‡u PDF")
    st.info("Vui lÃ²ng táº£i lÃªn vÃ  xá»­ lÃ½ file PDF á»Ÿ thanh Sidebar bÃªn trÃ¡i trÆ°á»›c khi Ä‘áº·t cÃ¢u há»i.")
    
    # Khá»Ÿi táº¡o session_state cho lá»‹ch sá»­ chat
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Ã” nháº­p cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
    user_question = st.chat_input("Äáº·t cÃ¢u há»i vá» tÃ i liá»‡u PDF báº¡n Ä‘Ã£ táº£i lÃªn...")

    if user_question:
        # Hiá»ƒn thá»‹ cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        with st.chat_message("user"):
            st.markdown(user_question)
        st.session_state.messages.append({"role": "user", "content": user_question})
        
        # Kiá»ƒm tra xem vector store Ä‘Ã£ sáºµn sÃ ng chÆ°a
        if "vector_store" not in st.session_state:
            st.warning("Vui lÃ²ng táº£i lÃªn vÃ  'Xá»­ lÃ½ TÃ i liá»‡u PDF' á»Ÿ Sidebar trÆ°á»›c khi Ä‘áº·t cÃ¢u há»i.")
        else:
            # Láº¥y cÃ¢u tráº£ lá»i tá»« AI
            with st.spinner("AI Ä‘ang tÃ¬m kiáº¿m trong tÃ i liá»‡u..."):
                response = answer_pdf_question(GEMINI_API_KEY, user_question)
                
                # Hiá»ƒn thá»‹ cÃ¢u tráº£ lá»i cá»§a AI
                with st.chat_message("assistant"):
                    st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})